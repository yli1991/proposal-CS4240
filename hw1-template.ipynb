{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer 2019 CX4240 Homework 1\n",
    "\n",
    "## Dr. Mahdi Roozbahani\n",
    "\n",
    "## Deadline: May 30, Thursday, 11:59 pm\n",
    "\n",
    "* No unapproved extension of the deadline is allowed. Late submission will lead to 0 credit. \n",
    "\n",
    "* Discussion is encouraged, but each student must write his own answers and explicitly mention any collaborators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions for the assignment\n",
    "\n",
    "In this assignment, we only have writing questions: you are asked to answer them in the markdown cells.\n",
    "\n",
    "- To switch between cell for code and for markdown, see the menu -> Cell -> Cell Type\n",
    "    \n",
    "- You could directly type the Latex equations in the markdown cell.\n",
    "\n",
    "- Typing with Latex is highly recommended. An image scan copy of handwritten also works. If you hand write, try to be clear as much as possible. No credit may be given to unreadable handwriting.\n",
    "    \n",
    "- If you want to add any picture to your answer, you could use this syntax $\"<img src=\"\" style=\"width: 300px;\"/>\"$ to include them within your ipython notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Eigenvalues and Eigenvectors for Bivariate Gaussian Distribution (25pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let two variables $X_1$ and $X_2$ are bivariately normally distributed with mean vector components $\\mu_1$ and $\\mu_2$ and co-variance matrix $\\Sigma$ shown below:\n",
    "   $$\\Sigma = \n",
    "   \\begin{bmatrix} \n",
    "    1 & r \\\\ \n",
    "    r & 1 \n",
    "    \\end{bmatrix}$$ \n",
    "\n",
    "- What is the probability distribution function of joint Gaussian $P(X_1, X_2)$? (show it with $\\mu$ and $\\Sigma$) [5pts]\n",
    "\n",
    "- What are the eigenvalues of co-variance matrix $\\Sigma$? [10pts]\n",
    "\n",
    "- Given the condition that norm (i.e. the sum of squared values) of each eigenvector is equal to 1, what are the eigenvectors of co-variance matrix $\\Sigma$? ( For example, if an eigenvector is \n",
    "    ${v_1}=\\begin{bmatrix} \n",
    "    x1 \\\\ \n",
    "    x2 \n",
    "    \\end{bmatrix}$, then $x_1^2 + x_2^2 = 1$) [10pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 1 :\n",
    "\n",
    "(1) the probability distribution function of joint Gaussian $P(X_1, X_2)$ is \n",
    "(2) the eigenvalues of co-variance matrix $\\Sigma$ is \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Expectation, Co-variance and Independence [25pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $X, Y$ and $Z$ are three different random variables.\n",
    "Let $X$ obeys Bernouli Distribution. The probability disbribution function is\n",
    "    $$p(x)=\\left\\{\n",
    "    \\begin{array}{c l}\t\n",
    "         0.5 & x = 1\\\\\n",
    "         0.5 & x = -1.\n",
    "    \\end{array}\\right.$$\n",
    "    \n",
    "Let $Y$ obeys the standard Normal (Gaussian) distribution, which can be written as $Y \\sim N(0,1)$. $X$ and $Y$ are independent. Meanwhile, let $Z = XY$.\n",
    "\n",
    "- What is the Expectation (mean value) of $X$? [3pts]\n",
    "- Are Y and Z independent? (Just clarify, do not need to prove) [2pts]\n",
    "- Show that $Z$ is also a standard Normal (Gaussian) distribution, which means $Z \\sim N(0,1)$. [10pts]\n",
    "- Are Y and Z uncorrelated(which means $Cov(Y,Z) = 0$)? (need to prove) [10pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Maximum Likelihood [25pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Discrete Example [17pts]\n",
    "Suppose you are playing two unfair coins. The probability of tossing a head is $2 \\theta$ for coin 1, and $\\theta$ for coin 2. You toss each coin for several times, and you get the following results:\n",
    "\n",
    "| Coin No. | Result    |\n",
    "|------|------|\n",
    "|   1  | head |\n",
    "|   2  | head |\n",
    "|   1  | tail |\n",
    "|   2  | tail |\n",
    "|   1  | head |\n",
    "|   2  | tail |\n",
    "\n",
    "- What is the probability of tossing a tail for coin 1 ($p_{t1}$) and tossing a tail for coin 2 ($p_{t2}$)[3pts]? \n",
    "\n",
    "- What is the likelihood of the data given $\\theta$ [7pts]?\n",
    "\n",
    "- What is maximum likelihood estimation for $\\theta$ [7pts]?\n",
    "\n",
    "### 3.2 Continues Example [8pts]\n",
    "\n",
    "A uniform distribution in the range of $[0, \\theta]$ is given by\n",
    "\n",
    "$$\n",
    "f(x)=\\left\\{\\begin{array}{ll}{\\frac{1}{\\theta}} & {0 \\leq x \\leq \\theta} \\\\ {0} & {\\text { otherwise }}\\end{array}\\right.\n",
    "$$\n",
    "What is maximum likelihood estimation for $\\theta$?\n",
    "( **hint**: Think of two cases, where $\\theta < max(x_1, x_2, ..., x_n)$ and $\\theta \\ge max(x_1, x_2, ..., x_n).)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Information Theory [25pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the joint probability distribution of two binary random variables $X$ and $Y$ are given as follows.\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\\hline X | Y & {1} & {2} \\\\ \\hline 0 & {\\frac{1}{4}} & {\\frac{1}{4}} \\\\ \\hline 1 & {\\frac{1}{2}} & {0} \\\\ \\hline\\end{array}\n",
    "$$\n",
    "\n",
    "- Show the marginal distribution of $X$. [2pts]\n",
    "- Find entropy $H(Y)$. [2pts]\n",
    "- Find conditional entropy $H(X|Y)$ and $H(Y|X)$. [3pts]\n",
    "- Find mutual information $I(X;Y)$. [3pts]\n",
    "- Find joint entropy $H(X, Y)$. [3pts]\n",
    "\n",
    "**Note:** The following three proofs are not related to the example in the above questions. You need to prove each for any general case.\n",
    "- Suppose $X$ and $Y$ are independent. Show that $H(X|Y) = H(X)$. [4pts]\n",
    "- Suppose $X$ and $Y$ are independent. Show that $H(X,Y) = H(X) + H(Y)$. [4pts]\n",
    "- Show that $I(X; X) = H(X)$. [4pts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
